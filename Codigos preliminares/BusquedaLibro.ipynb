{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo código de busqueda"
      ],
      "metadata": {
        "id": "Dj0d5TV5f1NE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se tomara como referencia una cadena que servirá como ejemplo de busqueda, se le aplicará una similitud coseno con la que obtendremos un libro del conjunto. A partir del libro obtenido, se hará uso de topic distribution para obtener libros relacionados al encontrado al principio."
      ],
      "metadata": {
        "id": "Q9fyetprf7yi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importacion de librerias"
      ],
      "metadata": {
        "id": "VEgIv9Ooga4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "wdFuQgDKW1l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "id": "DdmoWZIis30w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import spacy"
      ],
      "metadata": {
        "id": "kdUkbTIysk8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OsB6y_bLtNt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ajustables"
      ],
      "metadata": {
        "id": "_PvY9yAXgg6H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpQuYinMok5A"
      },
      "outputs": [],
      "source": [
        "consulta = \"El hombre no es nada. “Nuestra raza humana es solo un accidente trivial en la historia de la creación, escribió H. P. Lovecraft (Providence, Rhode Island, 1890- 1937), el autor ya de culto en cuyas obras el universo cobija la presencia abominable y repulsiva de criaturas omnipotentes y sin edad. Este volumen enfatiza a esos míticos seres cósmicos que han sellado el destino de la humanidad, mientras Cthulhu sueña y espera en la casa de R’lyeh. La obra de Lovecraft es una literatura ritual que produce una devastadora ansiedad y que hace de la repetición un mecanismo implacable. Se trata de una literatura cuyas huellas son imposibles de borrar.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_libros_tm_e = '/content/drive/MyDrive/ESCOM/8vo Semestre/NLP/librosTopicEmbeddings.csv'"
      ],
      "metadata": {
        "id": "x9SeBV9dqIuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementación"
      ],
      "metadata": {
        "id": "dW7KL00Lgms2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previamente se debió de haber limpiado y procesado el dataset. La variable `libros` almacena el .csv con los `topic distribution` y los `embeddings`.\n",
        "Además, se hace uso de `paraphrase-multilingual-mpnet-base-v2` como modelo para genera el embedding de la consulta (entrada)."
      ],
      "metadata": {
        "id": "X0Jfo6mDgsPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "libros = pd.read_csv(ruta_libros_tm_e)\n",
        "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
      ],
      "metadata": {
        "id": "LmAYG5UvqLkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalización de la consulta, se carga spacy en español"
      ],
      "metadata": {
        "id": "ji2mSomghVFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "\n",
        "def normalizacion (cadena):\n",
        "  doc = nlp(cadena)\n",
        "  texto_normalizado = \"\"\n",
        "  for token in doc:\n",
        "    if(not token.is_stop and not token.pos_=='SPACE'):\n",
        "      texto_normalizado += f\" {token.lemma_}\"\n",
        "\n",
        "  return texto_normalizado[1:]"
      ],
      "metadata": {
        "id": "ZYeZW4iBHEJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se crea el embedding de la consulta y se calcula la simulitud coseno y se almacena en el dataframe para posteriormente ordenar el mismo y obtener la instancia más similar"
      ],
      "metadata": {
        "id": "zym7R3r-hfVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences1 = [normalizacion(consulta)]\n",
        "\n",
        "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
        "embeddings2 = libros['Embeddings'].apply(lambda x: torch.tensor(eval(x)))\n",
        "\n",
        "embeddings2 = torch.stack(embeddings2.tolist())\n",
        "\n",
        "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
        "\n",
        "libros['Similitud_Coseno'] = cosine_scores[0].cpu().tolist()\n",
        "\n",
        "libro_seleccionado = libros[libros['Género']=='Terror y Suspenso'].sort_values('Similitud_Coseno', ascending=False).head(1)\n",
        "libro_seleccionado"
      ],
      "metadata": {
        "id": "GQSwi09TquVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir del libro obtenido, se extrae el `Topic Distribution` para calcular la distancia euclidiana con respecto a todos los libros del dataset y obtener los 5 más cernos."
      ],
      "metadata": {
        "id": "sTAIQrd_hyRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la distribución objetivo\n",
        "distribucion_objetivo = libro_seleccionado['Topic Distribution']\n",
        "#  {0: 0.583121915183577, 1: 0.0833352365882038, 2: 0.08333337663935135, 3: 0.08337779804310773, 4: 0.0833483889066023, 5: 0.08348328463915791}  # Ejemplo de distribución objetivo\n",
        "print(distribucion_objetivo)\n",
        "# Función para convertir el diccionario en un arreglo\n",
        "def dict_a_array(dict_dist, num_topics=6):\n",
        "    return np.array([dict_dist.get(i, 0) for i in range(num_topics)])\n",
        "\n",
        "# Función para calcular la distancia euclidiana\n",
        "def distancia_euclidiana(distribucion1, distribucion2):\n",
        "    return np.linalg.norm(distribucion1 - distribucion2)\n",
        "\n",
        "# Aplicar la conversión y calcular la distancia\n",
        "libros['Distancia'] = libros['Topic Distribution'].apply(lambda x: distancia_euclidiana(dict_a_array(eval(x)), dict_a_array(distribucion_objetivo)))\n",
        "\n",
        "# Encontrar la fila con la menor distancia\n",
        "top_5_mas_cercanos = libros[libros['Género']=='Terror y Suspenso'].sort_values('Distancia').head(5)\n",
        "top_5_mas_cercanos"
      ],
      "metadata": {
        "id": "vDDpnYduqevn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}